{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HL-x8Uc2G2Fu"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "usyE57L-jM4v"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import History\n",
        "from tensorflow.keras.models import save_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import *\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "API_KEY = os.getenv('API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4fDvSOerOUyL"
      },
      "outputs": [],
      "source": [
        "def rnn_model(time_step = 100):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(50, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(50))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "By6Wiy_SOZ4j"
      },
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_test, y_test , epochs = 100, batch_size = 64):\n",
        "  history = model.fit(X_train, y_train,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=1)\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9Kxi3fxjip2C"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prepare_and_train_model(symbol, api_key, time_step, epochs, batch_size):\n",
        "    # Fetch and preprocess data\n",
        "    df = fetch_stock_data(symbol, api_key)\n",
        "    data = preprocess_data(df)\n",
        "\n",
        "    # Scale data\n",
        "    scaled_data = scale_data(data)\n",
        "\n",
        "    # Split data into train and test\n",
        "    train_data, test_data, training_size, test_size = split_data(scaled_data)\n",
        "\n",
        "    # Create datasets for training/testing\n",
        "    X_train, y_train = create_dataset(train_data, time_step)\n",
        "    X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "    # Reshape inputs for RNN\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    # Create, train, and save model\n",
        "    model = rnn_model(time_step)\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs, batch_size)\n",
        "    model.save(f\"{symbol}_model.h5\")\n",
        "    print(f\"Model saved for {symbol}\")\n",
        "    return history,\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fu0sCFchiqi4"
      },
      "outputs": [],
      "source": [
        "def main(symbols, api_key, time_step=100 , epochs=100, batch_size=64 ):\n",
        "    histories ={}\n",
        "    for symbol in symbols:\n",
        "        try:\n",
        "           print(f\"Processing {symbol}\")\n",
        "           history = prepare_and_train_model(symbol, api_key, time_step, epochs, batch_size)\n",
        "           histories[symbol] = history\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {symbol}: {e}\")\n",
        "    return histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2eajyXSXy2N"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "symbols = [ 'GOOGL', 'AMZN', 'NVDA','MSFT' , 'TSLA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "inA5pXm-iule",
        "outputId": "105811d9-fe7f-403e-aa53-e8c10c5f78ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing GOOGL\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 164ms/step - loss: 0.0147 - val_loss: 0.0063\n",
            "Epoch 2/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 0.0010 - val_loss: 0.0070\n",
            "Epoch 3/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 8.9380e-04 - val_loss: 0.0048\n",
            "Epoch 4/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 8.6318e-04 - val_loss: 0.0049\n",
            "Epoch 5/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 7.6849e-04 - val_loss: 0.0043\n",
            "Epoch 6/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 9.0319e-04 - val_loss: 0.0043\n",
            "Epoch 7/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 174ms/step - loss: 6.9731e-04 - val_loss: 0.0041\n",
            "Epoch 8/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 148ms/step - loss: 5.6368e-04 - val_loss: 0.0040\n",
            "Epoch 9/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - loss: 6.4832e-04 - val_loss: 0.0038\n",
            "Epoch 10/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 6.1117e-04 - val_loss: 0.0053\n",
            "Epoch 11/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 174ms/step - loss: 6.9436e-04 - val_loss: 0.0040\n",
            "Epoch 12/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 5.2468e-04 - val_loss: 0.0033\n",
            "Epoch 13/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 5.2870e-04 - val_loss: 0.0039\n",
            "Epoch 14/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 174ms/step - loss: 5.1743e-04 - val_loss: 0.0031\n",
            "Epoch 15/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 4.4519e-04 - val_loss: 0.0032\n",
            "Epoch 16/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 4.2932e-04 - val_loss: 0.0033\n",
            "Epoch 17/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step - loss: 4.6544e-04 - val_loss: 0.0032\n",
            "Epoch 18/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 174ms/step - loss: 4.0963e-04 - val_loss: 0.0027\n",
            "Epoch 19/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 148ms/step - loss: 4.5308e-04 - val_loss: 0.0029\n",
            "Epoch 20/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 4.2557e-04 - val_loss: 0.0025\n",
            "Epoch 21/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step - loss: 4.3202e-04 - val_loss: 0.0027\n",
            "Epoch 22/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 3.5013e-04 - val_loss: 0.0026\n",
            "Epoch 23/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 4.0644e-04 - val_loss: 0.0025\n",
            "Epoch 24/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 149ms/step - loss: 3.2593e-04 - val_loss: 0.0023\n",
            "Epoch 25/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 176ms/step - loss: 3.6353e-04 - val_loss: 0.0024\n",
            "Epoch 26/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 3.6816e-04 - val_loss: 0.0025\n",
            "Epoch 27/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 3.3549e-04 - val_loss: 0.0023\n",
            "Epoch 28/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 176ms/step - loss: 3.7141e-04 - val_loss: 0.0021\n",
            "Epoch 29/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 3.4953e-04 - val_loss: 0.0024\n",
            "Epoch 30/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 3.2012e-04 - val_loss: 0.0023\n",
            "Epoch 31/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 3.2061e-04 - val_loss: 0.0021\n",
            "Epoch 32/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 2.6556e-04 - val_loss: 0.0021\n",
            "Epoch 33/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 2.8165e-04 - val_loss: 0.0022\n",
            "Epoch 34/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 2.8000e-04 - val_loss: 0.0019\n",
            "Epoch 35/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 177ms/step - loss: 2.6458e-04 - val_loss: 0.0019\n",
            "Epoch 36/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step - loss: 3.2206e-04 - val_loss: 0.0023\n",
            "Epoch 37/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 2.7990e-04 - val_loss: 0.0020\n",
            "Epoch 38/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 177ms/step - loss: 3.1758e-04 - val_loss: 0.0018\n",
            "Epoch 39/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 2.8958e-04 - val_loss: 0.0018\n",
            "Epoch 40/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 2.4847e-04 - val_loss: 0.0018\n",
            "Epoch 41/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 149ms/step - loss: 2.7099e-04 - val_loss: 0.0017\n",
            "Epoch 42/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 2.2694e-04 - val_loss: 0.0018\n",
            "Epoch 43/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 2.5820e-04 - val_loss: 0.0019\n",
            "Epoch 44/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 2.6358e-04 - val_loss: 0.0020\n",
            "Epoch 45/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 2.8199e-04 - val_loss: 0.0017\n",
            "Epoch 46/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 176ms/step - loss: 2.7336e-04 - val_loss: 0.0018\n",
            "Epoch 47/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 177ms/step - loss: 2.2065e-04 - val_loss: 0.0020\n",
            "Epoch 48/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step - loss: 2.5426e-04 - val_loss: 0.0015\n",
            "Epoch 49/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 2.3116e-04 - val_loss: 0.0015\n",
            "Epoch 50/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 2.5494e-04 - val_loss: 0.0016\n",
            "Epoch 51/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 2.5203e-04 - val_loss: 0.0015\n",
            "Epoch 52/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 177ms/step - loss: 2.0779e-04 - val_loss: 0.0015\n",
            "Epoch 53/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 176ms/step - loss: 2.0611e-04 - val_loss: 0.0014\n",
            "Epoch 54/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 2.3094e-04 - val_loss: 0.0014\n",
            "Epoch 55/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 2.6859e-04 - val_loss: 0.0014\n",
            "Epoch 56/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 2.0862e-04 - val_loss: 0.0014\n",
            "Epoch 57/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 172ms/step - loss: 2.4846e-04 - val_loss: 0.0016\n",
            "Epoch 58/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 3.0767e-04 - val_loss: 0.0014\n",
            "Epoch 59/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 2.3197e-04 - val_loss: 0.0014\n",
            "Epoch 60/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 2.0184e-04 - val_loss: 0.0015\n",
            "Epoch 61/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 2.1820e-04 - val_loss: 0.0015\n",
            "Epoch 62/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 170ms/step - loss: 2.1349e-04 - val_loss: 0.0014\n",
            "Epoch 63/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 2.3459e-04 - val_loss: 0.0014\n",
            "Epoch 64/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 176ms/step - loss: 2.3465e-04 - val_loss: 0.0013\n",
            "Epoch 65/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 2.4300e-04 - val_loss: 0.0014\n",
            "Epoch 66/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 2.1532e-04 - val_loss: 0.0012\n",
            "Epoch 67/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 2.2905e-04 - val_loss: 0.0012\n",
            "Epoch 68/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 2.3291e-04 - val_loss: 0.0013\n",
            "Epoch 69/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 177ms/step - loss: 2.1244e-04 - val_loss: 0.0012\n",
            "Epoch 70/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 2.3447e-04 - val_loss: 0.0013\n",
            "Epoch 71/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 2.3747e-04 - val_loss: 0.0012\n",
            "Epoch 72/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 175ms/step - loss: 1.8379e-04 - val_loss: 0.0011\n",
            "Epoch 73/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 1.9260e-04 - val_loss: 0.0011\n",
            "Epoch 74/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - loss: 2.1597e-04 - val_loss: 0.0012\n",
            "Epoch 75/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 2.1305e-04 - val_loss: 0.0011\n",
            "Epoch 76/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 175ms/step - loss: 2.0427e-04 - val_loss: 0.0012\n",
            "Epoch 77/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 1.9824e-04 - val_loss: 0.0014\n",
            "Epoch 78/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 172ms/step - loss: 2.3439e-04 - val_loss: 0.0011\n",
            "Epoch 79/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 2.4576e-04 - val_loss: 0.0011\n",
            "Epoch 80/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 2.1572e-04 - val_loss: 0.0012\n",
            "Epoch 81/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 2.1106e-04 - val_loss: 0.0013\n",
            "Epoch 82/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 2.5030e-04 - val_loss: 0.0014\n",
            "Epoch 83/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 2.5234e-04 - val_loss: 0.0011\n",
            "Epoch 84/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 1.9337e-04 - val_loss: 0.0014\n",
            "Epoch 85/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 177ms/step - loss: 2.3874e-04 - val_loss: 0.0010\n",
            "Epoch 86/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - loss: 2.0067e-04 - val_loss: 0.0011\n",
            "Epoch 87/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 2.2847e-04 - val_loss: 0.0011\n",
            "Epoch 88/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 2.3066e-04 - val_loss: 0.0013\n",
            "Epoch 89/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 1.9863e-04 - val_loss: 0.0011\n",
            "Epoch 90/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 1.9021e-04 - val_loss: 0.0011\n",
            "Epoch 91/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - loss: 2.1796e-04 - val_loss: 0.0010\n",
            "Epoch 92/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - loss: 2.0583e-04 - val_loss: 0.0010\n",
            "Epoch 93/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 2.1604e-04 - val_loss: 0.0010\n",
            "Epoch 94/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 2.1660e-04 - val_loss: 0.0010\n",
            "Epoch 95/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 2.4365e-04 - val_loss: 0.0011\n",
            "Epoch 96/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 1.9489e-04 - val_loss: 9.5466e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 165ms/step - loss: 2.0725e-04 - val_loss: 9.5727e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 176ms/step - loss: 1.7976e-04 - val_loss: 0.0010\n",
            "Epoch 99/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 1.9894e-04 - val_loss: 0.0010\n",
            "Epoch 100/100\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - loss: 2.0800e-04 - val_loss: 9.7803e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved for GOOGL\n",
            "Processing AMZN\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 174ms/step - loss: 0.0061 - val_loss: 0.0034\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - loss: 4.9869e-04 - val_loss: 0.0041\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 5.1580e-04 - val_loss: 0.0036\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 4.2933e-04 - val_loss: 0.0042\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 159ms/step - loss: 3.8968e-04 - val_loss: 0.0030\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 3.0965e-04 - val_loss: 0.0033\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - loss: 2.8726e-04 - val_loss: 0.0039\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 3.8498e-04 - val_loss: 0.0065\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 3.7458e-04 - val_loss: 0.0035\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 3.1135e-04 - val_loss: 0.0046\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 3.5046e-04 - val_loss: 0.0028\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 2.9256e-04 - val_loss: 0.0025\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 3.2859e-04 - val_loss: 0.0029\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 2.6093e-04 - val_loss: 0.0023\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 2.9611e-04 - val_loss: 0.0027\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 3.4425e-04 - val_loss: 0.0023\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 2.9770e-04 - val_loss: 0.0023\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 2.3953e-04 - val_loss: 0.0026\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 2.5768e-04 - val_loss: 0.0022\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 2.5313e-04 - val_loss: 0.0021\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 2.4566e-04 - val_loss: 0.0021\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 2.7842e-04 - val_loss: 0.0021\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 3.0193e-04 - val_loss: 0.0027\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 2.5466e-04 - val_loss: 0.0057\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - loss: 3.2280e-04 - val_loss: 0.0019\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 2.2489e-04 - val_loss: 0.0019\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 2.6513e-04 - val_loss: 0.0019\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 2.2696e-04 - val_loss: 0.0019\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 159ms/step - loss: 2.5354e-04 - val_loss: 0.0021\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 165ms/step - loss: 2.1743e-04 - val_loss: 0.0034\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 2.3461e-04 - val_loss: 0.0026\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 158ms/step - loss: 2.6959e-04 - val_loss: 0.0033\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 2.5110e-04 - val_loss: 0.0019\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 2.4832e-04 - val_loss: 0.0021\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 2.6560e-04 - val_loss: 0.0017\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 2.8907e-04 - val_loss: 0.0024\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 2.7479e-04 - val_loss: 0.0017\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - loss: 2.5528e-04 - val_loss: 0.0018\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 2.3256e-04 - val_loss: 0.0016\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 2.6312e-04 - val_loss: 0.0028\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 2.0873e-04 - val_loss: 0.0018\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 2.4809e-04 - val_loss: 0.0019\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 2.2288e-04 - val_loss: 0.0017\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 2.1570e-04 - val_loss: 0.0016\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 2.2696e-04 - val_loss: 0.0022\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 2.1321e-04 - val_loss: 0.0022\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 2.2321e-04 - val_loss: 0.0018\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 2.1353e-04 - val_loss: 0.0019\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 2.0393e-04 - val_loss: 0.0021\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 2.1171e-04 - val_loss: 0.0020\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - loss: 2.2795e-04 - val_loss: 0.0029\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 2.2752e-04 - val_loss: 0.0018\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 2.5253e-04 - val_loss: 0.0026\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 2.0662e-04 - val_loss: 0.0019\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 2.5402e-04 - val_loss: 0.0026\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 1.9042e-04 - val_loss: 0.0026\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 2.1255e-04 - val_loss: 0.0017\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - loss: 2.2197e-04 - val_loss: 0.0022\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - loss: 2.1953e-04 - val_loss: 0.0035\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 2.7916e-04 - val_loss: 0.0019\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 1.8733e-04 - val_loss: 0.0016\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 2.2620e-04 - val_loss: 0.0018\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 2.0873e-04 - val_loss: 0.0016\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - loss: 2.2947e-04 - val_loss: 0.0015\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 2.3082e-04 - val_loss: 0.0030\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 2.1614e-04 - val_loss: 0.0023\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 2.0227e-04 - val_loss: 0.0038\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 1.9494e-04 - val_loss: 0.0020\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 1.9464e-04 - val_loss: 0.0034\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 2.2825e-04 - val_loss: 0.0014\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 2.8821e-04 - val_loss: 0.0038\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 2.1837e-04 - val_loss: 0.0026\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 2.4334e-04 - val_loss: 0.0023\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - loss: 2.3248e-04 - val_loss: 0.0018\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 2.0539e-04 - val_loss: 0.0037\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 1.9928e-04 - val_loss: 0.0036\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 2.1087e-04 - val_loss: 0.0036\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 171ms/step - loss: 2.2326e-04 - val_loss: 0.0022\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 2.2889e-04 - val_loss: 0.0022\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 2.3896e-04 - val_loss: 0.0034\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 1.9202e-04 - val_loss: 0.0051\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 2.5192e-04 - val_loss: 0.0034\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 2.1389e-04 - val_loss: 0.0030\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 165ms/step - loss: 1.9857e-04 - val_loss: 0.0039\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 2.0342e-04 - val_loss: 0.0031\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 2.2786e-04 - val_loss: 0.0023\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 2.1013e-04 - val_loss: 0.0039\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 1.9922e-04 - val_loss: 0.0022\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 2.0464e-04 - val_loss: 0.0045\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 2.2012e-04 - val_loss: 0.0015\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 2.3849e-04 - val_loss: 0.0022\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 169ms/step - loss: 2.4787e-04 - val_loss: 0.0020\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 2.0059e-04 - val_loss: 0.0017\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 1.8246e-04 - val_loss: 0.0033\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 1.9463e-04 - val_loss: 0.0029\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - loss: 1.8681e-04 - val_loss: 0.0018\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 2.2051e-04 - val_loss: 0.0027\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 2.5331e-04 - val_loss: 0.0034\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 2.0407e-04 - val_loss: 0.0044\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - loss: 2.1317e-04 - val_loss: 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved for AMZN\n",
            "Processing NVDA\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 181ms/step - loss: 0.0012 - val_loss: 0.0070\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - loss: 1.2155e-04 - val_loss: 0.0067\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 1.0440e-04 - val_loss: 0.0069\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 9.9101e-05 - val_loss: 0.0055\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 8.6845e-05 - val_loss: 0.0054\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 163ms/step - loss: 8.8311e-05 - val_loss: 0.0051\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - loss: 8.0929e-05 - val_loss: 0.0048\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - loss: 8.3000e-05 - val_loss: 0.0049\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 7.6927e-05 - val_loss: 0.0044\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 7.0147e-05 - val_loss: 0.0046\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - loss: 7.2503e-05 - val_loss: 0.0041\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - loss: 7.4429e-05 - val_loss: 0.0046\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 165ms/step - loss: 8.4709e-05 - val_loss: 0.0039\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 158ms/step - loss: 9.8931e-05 - val_loss: 0.0038\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 5.5051e-05 - val_loss: 0.0045\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 7.7288e-05 - val_loss: 0.0036\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 6.7050e-05 - val_loss: 0.0033\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 6.0639e-05 - val_loss: 0.0033\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 6.6800e-05 - val_loss: 0.0035\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - loss: 5.6476e-05 - val_loss: 0.0033\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 6.0908e-05 - val_loss: 0.0032\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - loss: 6.0176e-05 - val_loss: 0.0029\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 5.5975e-05 - val_loss: 0.0036\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 6.3889e-05 - val_loss: 0.0028\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - loss: 5.3119e-05 - val_loss: 0.0027\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 162ms/step - loss: 6.7376e-05 - val_loss: 0.0029\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 5.7666e-05 - val_loss: 0.0025\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 5.1626e-05 - val_loss: 0.0026\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 4.8235e-05 - val_loss: 0.0028\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 4.8919e-05 - val_loss: 0.0025\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 5.4814e-05 - val_loss: 0.0024\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 4.7659e-05 - val_loss: 0.0023\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 159ms/step - loss: 5.5306e-05 - val_loss: 0.0023\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 162ms/step - loss: 5.4549e-05 - val_loss: 0.0022\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 5.1176e-05 - val_loss: 0.0023\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 5.0623e-05 - val_loss: 0.0023\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - loss: 4.3880e-05 - val_loss: 0.0023\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 4.8525e-05 - val_loss: 0.0022\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 5.1481e-05 - val_loss: 0.0020\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - loss: 5.5720e-05 - val_loss: 0.0024\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 4.7730e-05 - val_loss: 0.0020\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 5.3864e-05 - val_loss: 0.0019\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 4.3474e-05 - val_loss: 0.0019\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 5.0976e-05 - val_loss: 0.0019\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 4.6315e-05 - val_loss: 0.0019\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 5.2627e-05 - val_loss: 0.0026\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 5.1632e-05 - val_loss: 0.0021\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 4.5110e-05 - val_loss: 0.0018\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 5.0795e-05 - val_loss: 0.0017\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 169ms/step - loss: 4.6503e-05 - val_loss: 0.0020\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 5.1146e-05 - val_loss: 0.0017\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 4.5481e-05 - val_loss: 0.0017\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 4.7665e-05 - val_loss: 0.0018\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 4.0501e-05 - val_loss: 0.0018\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 4.2735e-05 - val_loss: 0.0017\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 4.8631e-05 - val_loss: 0.0017\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 4.6374e-05 - val_loss: 0.0019\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 3.7562e-05 - val_loss: 0.0018\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 4.2286e-05 - val_loss: 0.0017\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 4.1597e-05 - val_loss: 0.0023\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 3.9865e-05 - val_loss: 0.0015\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 4.5496e-05 - val_loss: 0.0017\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 4.1512e-05 - val_loss: 0.0020\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 4.7365e-05 - val_loss: 0.0017\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 4.3729e-05 - val_loss: 0.0018\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 3.6400e-05 - val_loss: 0.0020\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 162ms/step - loss: 4.2955e-05 - val_loss: 0.0015\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 5.0809e-05 - val_loss: 0.0015\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 3.9954e-05 - val_loss: 0.0014\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 4.1606e-05 - val_loss: 0.0016\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 4.9954e-05 - val_loss: 0.0015\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 4.8264e-05 - val_loss: 0.0017\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 3.7879e-05 - val_loss: 0.0015\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - loss: 4.5326e-05 - val_loss: 0.0016\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 4.6042e-05 - val_loss: 0.0018\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - loss: 4.2664e-05 - val_loss: 0.0014\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 4.2099e-05 - val_loss: 0.0020\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 4.4754e-05 - val_loss: 0.0016\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 3.4801e-05 - val_loss: 0.0015\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 4.0790e-05 - val_loss: 0.0016\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 3.5718e-05 - val_loss: 0.0015\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 4.0927e-05 - val_loss: 0.0018\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - loss: 4.6171e-05 - val_loss: 0.0015\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 4.7222e-05 - val_loss: 0.0017\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 3.7981e-05 - val_loss: 0.0017\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 4.1794e-05 - val_loss: 0.0020\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 3.9003e-05 - val_loss: 0.0024\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 4.1066e-05 - val_loss: 0.0019\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 3.9065e-05 - val_loss: 0.0022\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 4.1070e-05 - val_loss: 0.0017\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 4.7301e-05 - val_loss: 0.0014\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 3.7825e-05 - val_loss: 0.0018\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 4.1554e-05 - val_loss: 0.0015\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 3.5488e-05 - val_loss: 0.0020\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 4.0148e-05 - val_loss: 0.0017\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 3.7021e-05 - val_loss: 0.0016\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 3.5336e-05 - val_loss: 0.0017\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 3.7620e-05 - val_loss: 0.0014\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 4.2768e-05 - val_loss: 0.0018\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 4.2230e-05 - val_loss: 0.0016\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved for NVDA\n",
            "Processing MSFT\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 168ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 1.5669e-04 - val_loss: 0.0025\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 1.1049e-04 - val_loss: 0.0020\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 1.1846e-04 - val_loss: 8.8659e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - loss: 9.7054e-05 - val_loss: 0.0024\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 1.0138e-04 - val_loss: 6.6088e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 162ms/step - loss: 9.3185e-05 - val_loss: 0.0012\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 8.1982e-05 - val_loss: 7.2273e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 8.0572e-05 - val_loss: 0.0011\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 8.5573e-05 - val_loss: 5.4876e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 7.3751e-05 - val_loss: 5.0770e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 162ms/step - loss: 8.2502e-05 - val_loss: 0.0079\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 9.2036e-05 - val_loss: 5.3762e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 6.3374e-05 - val_loss: 0.0024\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 158ms/step - loss: 6.4826e-05 - val_loss: 0.0012\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 6.7886e-05 - val_loss: 4.9101e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - loss: 5.8598e-05 - val_loss: 0.0014\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 6.2776e-05 - val_loss: 5.5239e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - loss: 7.2545e-05 - val_loss: 0.0011\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 5.9242e-05 - val_loss: 6.0038e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 6.5409e-05 - val_loss: 9.3400e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - loss: 6.2282e-05 - val_loss: 8.0261e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 6.7536e-05 - val_loss: 5.8931e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 5.4334e-05 - val_loss: 4.2940e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 6.0705e-05 - val_loss: 0.0018\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 6.5590e-05 - val_loss: 4.7272e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 167ms/step - loss: 6.5152e-05 - val_loss: 4.6020e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 5.3601e-05 - val_loss: 4.2037e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 5.7867e-05 - val_loss: 4.7144e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 159ms/step - loss: 6.5995e-05 - val_loss: 7.2868e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 5.6352e-05 - val_loss: 0.0032\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 7.5616e-05 - val_loss: 3.6775e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 5.1226e-05 - val_loss: 3.3989e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - loss: 5.6360e-05 - val_loss: 3.7212e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - loss: 6.7067e-05 - val_loss: 9.2288e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 158ms/step - loss: 7.0143e-05 - val_loss: 0.0013\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - loss: 5.5833e-05 - val_loss: 3.8166e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - loss: 5.8682e-05 - val_loss: 9.0481e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 165ms/step - loss: 5.9651e-05 - val_loss: 8.0990e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 6.4300e-05 - val_loss: 6.3785e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 5.7313e-05 - val_loss: 0.0012\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 5.1239e-05 - val_loss: 0.0014\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 5.4238e-05 - val_loss: 4.7724e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 5.4755e-05 - val_loss: 3.2722e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 5.1242e-05 - val_loss: 4.3418e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 7.3954e-05 - val_loss: 0.0027\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 5.2859e-05 - val_loss: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - loss: 5.6993e-05 - val_loss: 0.0016\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 5.6378e-05 - val_loss: 0.0022\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 5.1886e-05 - val_loss: 6.4815e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 167ms/step - loss: 4.9613e-05 - val_loss: 4.6767e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - loss: 5.5853e-05 - val_loss: 0.0015\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 6.6793e-05 - val_loss: 9.3735e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 6.8021e-05 - val_loss: 7.9384e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 5.4749e-05 - val_loss: 3.4477e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 6.7596e-05 - val_loss: 6.4071e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 6.6356e-05 - val_loss: 3.1633e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 5.9145e-05 - val_loss: 0.0011\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 5.7150e-05 - val_loss: 3.6962e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 4.8372e-05 - val_loss: 0.0018\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 5.4906e-05 - val_loss: 4.1453e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 6.0875e-05 - val_loss: 4.6689e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 166ms/step - loss: 5.2974e-05 - val_loss: 4.4119e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 165ms/step - loss: 5.0328e-05 - val_loss: 0.0020\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 178ms/step - loss: 5.9458e-05 - val_loss: 0.0012\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - loss: 5.2491e-05 - val_loss: 3.2562e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - loss: 5.6380e-05 - val_loss: 3.7869e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 4.5258e-05 - val_loss: 0.0012\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 5.5523e-05 - val_loss: 0.0017\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 5.0225e-05 - val_loss: 0.0018\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 5.1404e-05 - val_loss: 5.1695e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 5.3002e-05 - val_loss: 9.0514e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 4.3107e-05 - val_loss: 0.0024\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - loss: 5.2410e-05 - val_loss: 4.3793e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 169ms/step - loss: 5.0964e-05 - val_loss: 8.5599e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 4.9457e-05 - val_loss: 0.0024\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 5.7040e-05 - val_loss: 6.0132e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 5.2380e-05 - val_loss: 5.0625e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 164ms/step - loss: 4.5543e-05 - val_loss: 8.8074e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 169ms/step - loss: 4.8276e-05 - val_loss: 0.0022\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 5.4328e-05 - val_loss: 0.0021\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - loss: 4.8781e-05 - val_loss: 6.9379e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - loss: 5.1052e-05 - val_loss: 0.0044\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - loss: 5.4161e-05 - val_loss: 8.6717e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 164ms/step - loss: 5.8390e-05 - val_loss: 8.2756e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - loss: 5.7593e-05 - val_loss: 0.0010\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 170ms/step - loss: 4.7318e-05 - val_loss: 0.0029\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 5.4676e-05 - val_loss: 0.0022\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 5.5461e-05 - val_loss: 0.0014\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 5.0048e-05 - val_loss: 0.0031\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - loss: 5.1080e-05 - val_loss: 0.0032\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 162ms/step - loss: 5.6589e-05 - val_loss: 0.0025\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 168ms/step - loss: 3.9511e-05 - val_loss: 0.0016\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 163ms/step - loss: 6.2155e-05 - val_loss: 0.0033\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - loss: 5.7435e-05 - val_loss: 0.0022\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - loss: 4.4187e-05 - val_loss: 0.0032\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 169ms/step - loss: 5.0487e-05 - val_loss: 0.0031\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - loss: 5.0171e-05 - val_loss: 0.0045\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 168ms/step - loss: 4.9888e-05 - val_loss: 0.0015\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 5.7750e-05 - val_loss: 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved for MSFT\n",
            "Processing TSLA\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - loss: 0.0098 - val_loss: 2.9055e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 185ms/step - loss: 0.0019 - val_loss: 1.6738e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 0.0022 - val_loss: 1.6417e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 165ms/step - loss: 0.0015 - val_loss: 1.6410e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - loss: 0.0016 - val_loss: 2.1496e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - loss: 0.0014 - val_loss: 2.3047e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 172ms/step - loss: 0.0018 - val_loss: 1.3084e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - loss: 0.0015 - val_loss: 1.1220e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - loss: 0.0015 - val_loss: 4.9724e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - loss: 0.0012 - val_loss: 8.4544e-05\n",
            "Epoch 11/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0011 - val_loss: 2.2167e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 8.3878e-04 - val_loss: 2.0421e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 173ms/step - loss: 8.5202e-04 - val_loss: 1.3110e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - loss: 9.4157e-04 - val_loss: 8.0517e-05\n",
            "Epoch 15/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 176ms/step - loss: 9.5950e-04 - val_loss: 1.3560e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 167ms/step - loss: 8.8346e-04 - val_loss: 1.7405e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - loss: 7.7962e-04 - val_loss: 9.3967e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 174ms/step - loss: 7.6873e-04 - val_loss: 1.5692e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - loss: 7.8391e-04 - val_loss: 6.7525e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - loss: 6.6255e-04 - val_loss: 1.5584e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 8.0338e-04 - val_loss: 1.2049e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 177ms/step - loss: 8.0891e-04 - val_loss: 1.7700e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 9.8958e-04 - val_loss: 6.7214e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 178ms/step - loss: 6.4672e-04 - val_loss: 2.3134e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - loss: 6.2847e-04 - val_loss: 5.9658e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - loss: 6.7080e-04 - val_loss: 7.6627e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 5.6809e-04 - val_loss: 7.7375e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 168ms/step - loss: 7.6111e-04 - val_loss: 1.0822e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - loss: 5.2157e-04 - val_loss: 6.1469e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 174ms/step - loss: 8.1879e-04 - val_loss: 6.4014e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - loss: 5.9608e-04 - val_loss: 8.7133e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 182ms/step - loss: 7.7355e-04 - val_loss: 6.8401e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 5.3883e-04 - val_loss: 5.7494e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - loss: 7.8331e-04 - val_loss: 1.1083e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - loss: 6.1898e-04 - val_loss: 6.2575e-05\n",
            "Epoch 36/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 6.6675e-04 - val_loss: 5.8870e-05\n",
            "Epoch 37/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 173ms/step - loss: 7.0483e-04 - val_loss: 6.3078e-05\n",
            "Epoch 38/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 171ms/step - loss: 5.3419e-04 - val_loss: 9.2813e-05\n",
            "Epoch 39/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 147ms/step - loss: 6.3559e-04 - val_loss: 7.4390e-05\n",
            "Epoch 40/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - loss: 0.0011 - val_loss: 7.0782e-05\n",
            "Epoch 41/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 176ms/step - loss: 9.7247e-04 - val_loss: 6.0384e-05\n",
            "Epoch 42/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 173ms/step - loss: 5.3034e-04 - val_loss: 7.0296e-05\n",
            "Epoch 43/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 8.6481e-04 - val_loss: 8.6060e-05\n",
            "Epoch 44/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - loss: 5.3220e-04 - val_loss: 7.1476e-05\n",
            "Epoch 45/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 177ms/step - loss: 7.9702e-04 - val_loss: 6.0753e-05\n",
            "Epoch 46/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 174ms/step - loss: 5.3345e-04 - val_loss: 8.5824e-05\n",
            "Epoch 47/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 6.8480e-04 - val_loss: 6.4516e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 163ms/step - loss: 5.2891e-04 - val_loss: 6.1036e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 5.0013e-04 - val_loss: 6.2287e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - loss: 6.7355e-04 - val_loss: 5.6882e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 177ms/step - loss: 0.0011 - val_loss: 6.4806e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 174ms/step - loss: 7.1051e-04 - val_loss: 5.4795e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - loss: 5.0121e-04 - val_loss: 5.6176e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 5.0507e-04 - val_loss: 6.4554e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 177ms/step - loss: 5.4041e-04 - val_loss: 5.2187e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 4.5177e-04 - val_loss: 7.9512e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 152ms/step - loss: 4.9858e-04 - val_loss: 8.1255e-05\n",
            "Epoch 58/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 4.0458e-04 - val_loss: 5.5813e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - loss: 5.5901e-04 - val_loss: 8.7249e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 176ms/step - loss: 5.1994e-04 - val_loss: 7.1974e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 165ms/step - loss: 7.8011e-04 - val_loss: 6.3923e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 5.1337e-04 - val_loss: 6.8066e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - loss: 7.8837e-04 - val_loss: 5.1203e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - loss: 4.7336e-04 - val_loss: 6.5325e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 178ms/step - loss: 8.2010e-04 - val_loss: 4.9464e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 175ms/step - loss: 4.6765e-04 - val_loss: 5.2427e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - loss: 3.8607e-04 - val_loss: 7.4985e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 6.4683e-04 - val_loss: 5.0678e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 4.5143e-04 - val_loss: 6.8868e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 203ms/step - loss: 9.8445e-04 - val_loss: 6.9534e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - loss: 4.9925e-04 - val_loss: 6.0921e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 152ms/step - loss: 3.7992e-04 - val_loss: 4.9815e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 149ms/step - loss: 5.6115e-04 - val_loss: 6.4579e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 5.7878e-04 - val_loss: 6.1645e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 176ms/step - loss: 6.0319e-04 - val_loss: 5.2021e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - loss: 4.0208e-04 - val_loss: 5.2515e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - loss: 4.5409e-04 - val_loss: 4.8221e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - loss: 7.0340e-04 - val_loss: 7.9091e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step - loss: 6.4562e-04 - val_loss: 7.2775e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 180ms/step - loss: 4.4291e-04 - val_loss: 5.3274e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 154ms/step - loss: 4.7337e-04 - val_loss: 4.6005e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 3.5704e-04 - val_loss: 4.6219e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 179ms/step - loss: 7.4581e-04 - val_loss: 5.2139e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - loss: 5.8309e-04 - val_loss: 5.3433e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - loss: 4.7880e-04 - val_loss: 4.7111e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 178ms/step - loss: 5.6232e-04 - val_loss: 5.1130e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 179ms/step - loss: 6.3453e-04 - val_loss: 4.3573e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - loss: 3.2902e-04 - val_loss: 4.5957e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 6.5015e-04 - val_loss: 4.8055e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - loss: 4.1015e-04 - val_loss: 5.6568e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 160ms/step - loss: 7.9163e-04 - val_loss: 5.1769e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 178ms/step - loss: 4.2936e-04 - val_loss: 6.3952e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 179ms/step - loss: 4.7968e-04 - val_loss: 4.2975e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - loss: 7.1967e-04 - val_loss: 5.4160e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 151ms/step - loss: 4.9838e-04 - val_loss: 4.3180e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 179ms/step - loss: 4.3530e-04 - val_loss: 5.4201e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - loss: 4.5951e-04 - val_loss: 4.4924e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - loss: 3.7386e-04 - val_loss: 5.6364e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 5.6357e-04 - val_loss: 5.4363e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 5.7192e-04 - val_loss: 5.0313e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved for TSLA\n"
          ]
        }
      ],
      "source": [
        "histories = main(symbols, API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "REMz3UcKivKI"
      },
      "outputs": [],
      "source": [
        "def plot_loss_graphs(histories):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    for symbol, history in histories.items():\n",
        "        loss = history.history['loss']\n",
        "        val_loss = history.history.get('val_loss', None)\n",
        "\n",
        "        plt.plot(loss, label=f'{symbol} Train Loss')\n",
        "        if val_loss:\n",
        "            plt.plot(val_loss, linestyle='--', label=f'{symbol} Val Loss')\n",
        "        plt.title('Training and Validation Loss per Symbol')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FImvLVbnWrzy"
      },
      "outputs": [],
      "source": [
        "plot_loss_graphs(histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ToWuQUCmgppE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('MSFT_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f8nq-uvjFx3"
      },
      "outputs": [],
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = scaler.inverse_transform(y_predicted)\n",
        "y_actual = scaler.inverse_transform(y_test.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-p0fb9kmjfQ9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(f'APPL - Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ceWmeDsGlOt-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_actual, label='Actual Price')\n",
        "plt.plot(y_predicted, label='Predicted Price')\n",
        "plt.title('Appl - Actual vs Predicted')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELQyMFY3mG1V"
      },
      "outputs": [],
      "source": [
        "total_loss = history.history['loss'] + history_2.history['loss']\n",
        "\n",
        "# Combine validation losses (if used)\n",
        "if 'val_loss' in history.history:\n",
        "    total_val_loss = history.history['val_loss'] + history_2.history['val_loss']\n",
        "else:\n",
        "    total_val_loss = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-4jB9_D30M9b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(total_loss, label='Training Loss')\n",
        "plt.plot(total_val_loss, label='Validation Loss')\n",
        "plt.title('Combined Training Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "enve",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
